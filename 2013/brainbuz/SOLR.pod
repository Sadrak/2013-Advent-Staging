=head1 TITLE

Using SOLR in a Catalyst Model with WebService::Solr

=head1 OVERVIEW

Using L<Solr|http://lucene.apache.org/Solr/>, a Search Server from L<Apache's Lucene Project|http://lucene.apache.org> as a B<Catalyst Model>.

=head1 INTRODUCTION

Compared to conventional database search (and the full text query extensions found in most modern SQL implementations), a Search Server is going to provide better performance and search features. Since Solr is writeable as well as readable it can be used as a NoSQL datastore. 

=head2 Solr Basics

Solr is a java servelet, implementing a web based interface to Lucene. Requests to Solr are made via http requests. Request data may be sent in either post or get values. Data is returned in json but Solr will also return data in xml or csv formats. Similarly posts of data to Solr may be in any of these formats. Lucene provides indexing and search technology, as well as spellchecking, hit highlighting and advanced analysis/tokenization capabilities. The Data Import Handler will allow you to import from lots of other sources rather than needing to post it all through web requests. Once up and going it gives you a lot of possibilities for finding documents. 

=head2 Alternatives To Solr

The most obvious alternative to Solr is direct implementation of Lucene. Since the purpose of Solr is to provide a more useable interface to Lucene in the first place, this does not seem like a good way to get started. An Alternative to Solr that is also built on Lucene is L<ElasticSearch|http://www.elasticsearch.org>. At this time there is far more written about Solr and I did not experiment with ElasticSearch. There is an official Elasticsearch module on CPAN which seems to be under very active development. 

Google Search Appliances offerings are expensive and have a lot of functionality limitations, Google also has a cloud based search offering, which has considerably less features than the appliance. The cheap google alternative is to point your visitors at google.com with a site qualifier in the redirect (or any other public search engine). For a lot of developers the AWS CloudSearch service is going to be of great interest, while not free as Solr is, the administrative costs will for most enterprises make it the cheaper choice vs Solr or Google Appliance, on the downside it has a far more limited feature set than Solr and does not offer the option of going under the hood as Lucene provides to Solr. 

=head2 Perl Modules

There are a number of Perl Modules available for Solr, the two that appear the most viable are Apache::Solr and WebService::Solr. Unfortunately,
all of the modules have problems both in bugs and unimplemented features. Initally I had the best luck with Apache::Solr but ran into some limitations there. After reading through the source code several of the modules, I decided to work with WebService::Solr. At present it looks like Apache::Solr is being more actively developed so in the future it could overtake WebService::Solr.

=head1 Preparing the Environment

You will need to have a Catalyst Development Environment ready, in addition you should install WebService::Solr and Catalyst::Model::WebService::Solr. 
Catalyst 5.90050 introduced a new configuration setting to help with unicode compatibility. If updating Catalyst isn't an option for you the workaround I was using is detailed in rtcpan bug 89288. I also strongly recommend using the latest Perl. 

You will also need to install a JVM like open JDK and then download a copy of Solr from L<http://lucene.apache.org/solr/downloads.html|http://lucene.apache.org/solr/downloads.html>.  Once downloaded and extracted you will need to load the example data. Open up two terminals. To save space I'll refer you to the Solr tutorial, to speed up use post.sh in the exampledocs folder to populate the test data, and skip ahead to querying to confirm that you have loaded the 32 documents. For the purpose of the rest of the article it will be assumed you have solr running locally with the test data loaded and answering the default port 8983 ,
 
 Terminal 1
 cd ..path_to../example
 java -jar start.jar
 
 Terminal 2
 cd ..path_to../example/exampledocs
 ./post.sh *.xml

=head1 Create A Project with a Template Toolkit View

 catalyst.pl SolrDemo
 cd SolrDemo
 ./script/solrdemo_create.pl view HTML TT
 
Edit the SolrDemo.conf files

 solrserver         http://localhost:8983/solr/collection1

Edit the config section of lib/SolrDemo.pm 

 __PACKAGE__->config(
    name => 'SolrDemo',
    # Disable deprecated behavior needed by old applications
    disable_component_resolution_regex_fallback => 1,
    enable_catalyst_header => 1, # Send X-Catalyst header
    encoding => 'utf8', # prevents wide character explosions
    'View::HTML' => {  #Set the location for TT files        
         INCLUDE_PATH => [ CalEvt->path_to( 'root' ), ], },    
 );

Create the additional files we'll need

 touch lib/SolrDemo/Model/Solr.pm
 touch lib/SolrDemo/Model/SolrModelSolr.pm
 touch lib/SolrDemo/Controller/Thin.pm
 touch lib/SolrDemo/Controller/Thin.pm 
 touch root/results.tt
 touch t/model_solr.t
 
=head1 A Thin Model with Catalyst::Model::WebService::Solr

File: lib/SolrDemo/Controller/Thin.pm 

    package SolrDemo::Controller::Thin;
    use namespace::autoclean;
    use WebService::Solr::Query;
    use Moose;

    BEGIN { extends 'Catalyst::Controller' }

    sub response2info {
        my $response = shift;
        my $raw      = $response->raw_response();
        my $pre      = '';
        $pre .= "\n_msg\n" . $raw->{'_msg'};
        $pre .= "\n_headers";
        my %hheaders = %{ $raw->{'_headers'} };
        for ( keys %hheaders ) { $pre .= "\n    $_ = $hheaders{$_}"; }
        $pre .= "\n_request";
        my %rreq = %{ $raw->{'_request'} };
        for ( keys %rreq ) { $pre .= "\n    $_ = $rreq{$_}"; }
        $pre .= "\n_content</pre>\n" . $raw->{'_content'} . '<pre>';
        $pre .= "\n_rc\n" . $raw->{'_rc'};
        $pre .= "\n_protocol\n" . $raw->{'_protocol'};
        $pre .= "\nRequest Status (via method)\n" . $response->solr_status();
        my @docs = $response->docs;
        $pre .= "\nDocument Count: " . scalar(@docs);
        return $pre;
    }

    sub dump : Local : Args(0) {
        my ( $self, $c ) = @_;
        my $response =
        $c->model('SolrModelSolr')
        ->search( WebService::Solr::Query->new( { '*' => \'*' } ),
            { rows => 10000 } );
        my @docs = $response->docs;
        $c->log->info( "\nDocument Count: " . scalar(@docs) );
        my $pre = &response2info($response);
        $c->response->body("<pre>$pre </pre>");
    }

    sub select : Local : Args(0) {
        my ( $self, $c ) = @_;
        my $response =
        $c->model('SolrModelSolr')
        ->search( WebService::Solr::Query->new( { text => ['hard drive'] } ),
            { rows => 10000 } );
        my $pre = &response2info($response);
        $c->response->body("<pre>$pre </pre>");
    }

    __PACKAGE__->meta->make_immutable;

    1;

=head2 About the thin controller

=head3 response2info

The response2info sub consolidates code that would have been repeated by both methods. Functionally this is view code, but I'm not using a view, for convenience it goes here. What we're doing with this method is a raw dump of everything returned by WebService::Solr. 

=head3 dump

Executes a query for all records in the solr database. Notice that we need WebService::Solr::Query to help generate queries, I've proposed a shortcut for what you see in the first argument. To generate the query you need to pass a hashref of the solr fields you want and the values for the fields, the \ indicates to pass the second * as a literal string. The second argument is a hashref of options, here we need to override the solr default of returning 10 rows by specifying an arbitrary high value.

=head3 select

This select query is hard coded to find items matching the phrase 'hard drive', which, we see from the spew, gets translated as 'hard+drive'. Here we specified the field text (which is a catch-all field defined to hold everything searchable) and passed an array ref to the list of values. If you copy and rename the method and then change the field list to C<['hard drive','maxtor']>, you will find that you still get the same 2 records, this is because of solr's matching behaviour. If you want to filter for only maxtor hard drives you'll need to use a filter query which is specified in the options.

Add the following method to Thin.pm

    sub maxtor :Local :Args(0) {
        my ( $self, $c ) = @_;
        my $maxq = WebService::Solr::Query->new( { manu => ['maxtor'] } );
        my $response =
        $c->model('SolrModelSolr')
        ->search( WebService::Solr::Query->new( { text => ['hard drive'] } ),
            { rows => 10000, fq => $maxq } );
        my $pre = &response2info($response);
        $c->response->body("<pre>$pre </pre>");
    } 
    
=head3 a real search

Add this method to Thin.pm

    sub realquery : Local : Args(2) {
        my ( $self, $c, $fieldname, $fieldvalue ) = @_;
        my $response =
        $c->model('SolrModelSolr')
        ->search( WebService::Solr::Query->new( { $fieldname => [$fieldvalue] } ),
            { rows => 10000 } );
        my @docs = $response->docs;
        $c->stash(
            template => 'results.tt',
            field    => $fieldname,
            value    => $fieldvalue,
            docs     => \@docs
        );
    }

Edit /root/results.tt    

    <h1>Catalyst SolrDemo</h1>
    <h2>Docs in this query [% doc_count %]</h2>
    <h3>Field [% field %] value [%value %]</h3>
    <table>
    [% FOREACH doc IN docs %]
    <tr><th>descriptor</th><th>field value</th></tr>
    [% FOREACH fieldname IN doc.field_names.sort %]
    <tr><td>[% fieldname %]</td><td>[% doc.value_for( fieldname ) %]</td></tr>
    [% END %]
    [% END %]
    </table>

Try some queries: http://localhost:3000/thin/realquery/text/ipod  http://localhost:3000/thin/realquery/features/cache http://localhost:3000/thin/realquery/manu/maxtor

First the model returns a WebService::Solr::Response object, we use the docs method to extract an array of WebService::Solr::Document objects from it which are then passed by reference to the view. The view iterates the array and uses the C<fieldnames> method to get a list of the fields in that document (not all documents in the test data have the same fields) and then iterates through it finally retrieving individual fields with the C<value_for method>.

=head1 Moving to a Fat Model

My solr search queries typically require a lot of supporting code, which is easier to test in a model than a controller, and is generally more appropriate to the model. Unlike DBI based models which maintain a connection, each request to solr is completely independent of all others and no connection is maintained between them, so instantiating a new WebService::Solr object is relatively trivial, additionally if you work with multiple collections you need to create a seperate object for each one. 

lib/SolrDemo/Model/Solr.pm

    package SolrDemo::Model::Solr;

    use WebService::Solr;
    use WebService::Solr::Query;
    use namespace::autoclean;

    use parent 'Catalyst::Model';

    our $SOLR = WebService::Solr->new( SolrDemo->config->{solrserver} );

    sub _GeoFilter {
        my ( $location, $sfield, $distance ) = @_;
        return qq/\{!geofilt pt=$location sfield=$sfield d=$distance\}/;
    }

    sub List {
        my $self      = shift;
        my $params    = shift;
        my $mainquery = WebService::Solr::Query->new($params);
        my %options   = ( rows => 100 );
        my $response  = $SOLR->search( $mainquery, \%options );
        return $response->docs;
    }

    sub Kimmel {
        my $self         = shift;
        my $distance     = shift;
        my $kimmelcenter = '39.95,-75.16';
        my $mainquery    = WebService::Solr::Query->new( { '*' => \'*' } );
        my $geofilt      = &_GeoFilter( $kimmelcenter, 'store', $distance );
        my %options      = ( rows => 100, fq => $geofilt );
        my $response     = $SOLR->search( $mainquery, \%options );
        return $response->docs;
    }

    1;

t/model_solr.t

    use Test::More;         
                    
    BEGIN { use_ok 'SolrDemo' }

    my $C = SolrDemo->new ;
    my @docs = $C->model('Solr')->List( { cat => 'electronics', manu => 'corsair' } );
    is( scalar(@docs), 2, 'We expect 2 docs' );

    my $carnegiehall = '40.76,-73.98' ;
    my $geofilt = &SolrDemo::Model::Solr::_GeoFilter( $carnegiehall, 'store', 400 ) ;
    is( $geofilt, '{!geofilt pt=40.76,-73.98 sfield=store d=400}', 'Test geofilter construction using carnegie hall as a testcase');
    my @docs2 = $C->model('Solr')->Kimmel( 1600 ) ;
    is( scalar(@docs2), 3, 'There are 3 items within 1600 km of the Kimmel Center' );

    done_testing();

lib/SolrDemo/Controller/Fat.pm

    package SolrDemo::Controller::Fat;
    use namespace::autoclean;
    use WebService::Solr::Query;
    use Moose;

    BEGIN { extends 'Catalyst::Controller' }

    sub realquery : Local : Args(2) {
        my ( $self, $c, $fieldname, $fieldvalue ) = @_;
        my @docs = $c->model('Solr')->List( { $fieldname => $fieldvalue } );
        $c->stash(
            template => 'results.tt',
            field    => $fieldname,
            value    => $fieldvalue,
            docs     => \@docs
        );
    }

    sub nearkimmel : Local : Args() {
        my ( $self, $c ) = @_;
        my $distance = 500;
        my @docs     = $c->model('Solr')->Kimmel(500);
        $c->stash(
            template => 'results.tt',
            field    => 'Distance from Kimmel Center in Philadelphia',
            value    => $distance,
            docs     => \@docs
        );
    }

    __PACKAGE__->meta->make_immutable;

    1;

Because I write my models from test, I'm going to test test two public and 1 private methods first. The private method generates a geofilter string, because that isn't currently implemented in WebService::Solr, but I've proposed it for a future release. In the fat model I it is easy to directly test possible queries against my code. I've written two methods, the first (realquery) does exactly the same as the method in the thin controller. It takes a few more lines in the fat model because I feel less urgency to be terse, and I find it easier to pick apart the bits of a complex query when each piece is sitting in its own variable. The second method (Kimmel) uses a geofilter to find the number of items within 500km of the Kimmel Center in Philadelphia. Finally with the models tested the methods are dropped into the Controller.

=head1 For More Information

After following this how-to document you'll want to read the WebService::Solr Documentation. It is organized by sub-module so you probably need to read through it several times to fit everything together. 

=head1 Summary

In this article we created both Thin and Fat Models for SOLR and wrote a few tests for our Fat Model. 

=head1 Author

John Karr <brainbuz@brainbuz.org> brainbuz

=cut
